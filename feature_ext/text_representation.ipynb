{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd8c3920",
   "metadata": {},
   "source": [
    "#  Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e0e7e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'text': ['people watch campus', 'campus watch campus', 'hello brother'], 'output': [1, 0, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0db3e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campus watch campus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello brother</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text  output\n",
       "0  people watch campus       1\n",
       "1  campus watch campus       0\n",
       "2        hello brother       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50add9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "text = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d448225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': 3, 'watch': 4, 'campus': 1, 'hello': 2, 'brother': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alphabetically kon pahle aayega ye batata hai\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05338d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 7 stored elements and shape (3, 5)>\n",
      "  Coords\tValues\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 1)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 1)\t2\n",
      "  (2, 2)\t1\n",
      "  (2, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5874a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1]]\n",
      "[[0 2 0 0 1]]\n",
      "[[1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# toarray means here = total array\n",
    "print(text[0].toarray())\n",
    "print(text[1].toarray())\n",
    "print(text[2].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a19f6ed",
   "metadata": {},
   "source": [
    "For binary = true and max_feautre in countvectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5bb6a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1]]\n",
      "[[0 1 0 0 1]]\n",
      "[[1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv1 = CountVectorizer(binary = True)\n",
    "text = cv1.fit_transform(df['text'])\n",
    "print(text[0].toarray())\n",
    "print(text[1].toarray())\n",
    "print(text[2].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "261e5a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[[2]]\n",
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "cv2 = CountVectorizer(max_features = 1)\n",
    "text = cv2.fit_transform(df['text'])\n",
    "print(text[0].toarray())\n",
    "print(text[1].toarray())\n",
    "print(text[2].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42432a",
   "metadata": {},
   "source": [
    "# N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4971e76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1]]\n",
      "[[1 0 0 1]]\n",
      "[[0 1 0 0]]\n",
      "{'people watch': 2, 'watch campus': 3, 'campus watch': 0, 'hello brother': 1}\n"
     ]
    }
   ],
   "source": [
    "cv3 = CountVectorizer(ngram_range = (2, 2)) # bigram\n",
    "\n",
    "text = cv3.fit_transform(df['text'])\n",
    "print(text[0].toarray())\n",
    "print(text[1].toarray())\n",
    "print(text[2].toarray())\n",
    "print(cv3.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b797ef3",
   "metadata": {},
   "source": [
    "If in ngram_range = (1, 2) then both unigram and bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f255c6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 1 1 1 1]]\n",
      "[[0 2 1 0 0 0 0 1 1]]\n",
      "[[1 0 0 1 1 0 0 0 0]]\n",
      "{'people': 5, 'watch': 7, 'campus': 1, 'people watch': 6, 'watch campus': 8, 'campus watch': 2, 'hello': 3, 'brother': 0, 'hello brother': 4}\n"
     ]
    }
   ],
   "source": [
    "cv4 = CountVectorizer(ngram_range = (1, 2)) # bigram\n",
    "\n",
    "text = cv4.fit_transform(df['text'])\n",
    "print(text[0].toarray())\n",
    "print(text[1].toarray())\n",
    "print(text[2].toarray())\n",
    "\n",
    "print(cv4.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a137e2f",
   "metadata": {},
   "source": [
    "#  Custom features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21faf1fc",
   "metadata": {},
   "source": [
    "Could make feautres like ve words, _ve words, word count, ratio of the +/- words etc. etc. depends on project we are working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4302dbb6",
   "metadata": {},
   "source": [
    "# WORD2VEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a91b0e9",
   "metadata": {},
   "source": [
    "Using pre trained model of word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ab28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\myind\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# importing pre trained model\n",
    "%pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "557248e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1901103729.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mcurl -O https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\u001b[39m\n            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# importing google news dataset\n",
    "curl -O https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49aa9586",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mKeyedVectors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGoogleNews-vectors-negative300.bin.gz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myind\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1721\u001b[39m, in \u001b[36mKeyedVectors.load_word2vec_format\u001b[39m\u001b[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[39m\n\u001b[32m   1674\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1675\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_word2vec_format\u001b[39m(\n\u001b[32m   1676\u001b[39m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab=\u001b[38;5;28;01mNone\u001b[39;00m, binary=\u001b[38;5;28;01mFalse\u001b[39;00m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf8\u001b[39m\u001b[33m'\u001b[39m, unicode_errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1677\u001b[39m         limit=\u001b[38;5;28;01mNone\u001b[39;00m, datatype=REAL, no_header=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1678\u001b[39m     ):\n\u001b[32m   1679\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[32m   1680\u001b[39m \n\u001b[32m   1681\u001b[39m \u001b[33;03m    Warnings\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1719\u001b[39m \n\u001b[32m   1720\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1721\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myind\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2050\u001b[39m, in \u001b[36m_load_word2vec_format\u001b[39m\u001b[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[39m\n\u001b[32m   2047\u001b[39m             counts[word] = \u001b[38;5;28mint\u001b[39m(count)\n\u001b[32m   2049\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mloading projection weights from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, fname)\n\u001b[32m-> \u001b[39m\u001b[32m2050\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[32m   2051\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m no_header:\n\u001b[32m   2052\u001b[39m         \u001b[38;5;66;03m# deduce both vocab_size & vector_size from 1st pass over file\u001b[39;00m\n\u001b[32m   2053\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m binary:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myind\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\smart_open\\smart_open_lib.py:217\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(ve.args[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m binary = \u001b[43m_open_binary_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransport_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m filename = (\n\u001b[32m    219\u001b[39m     binary.name\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# if name attribute is not string-like (e.g. ftp socket fileno)...\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    223\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[32m    224\u001b[39m )\n\u001b[32m    225\u001b[39m decompressed = so_compression.compression_wrapper(\n\u001b[32m    226\u001b[39m     binary,\n\u001b[32m    227\u001b[39m     binary_mode,\n\u001b[32m    228\u001b[39m     compression,\n\u001b[32m    229\u001b[39m     filename=filename,\n\u001b[32m    230\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myind\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\smart_open\\smart_open_lib.py:405\u001b[39m, in \u001b[36m_open_binary_stream\u001b[39m\u001b[34m(uri, mode, transport_params)\u001b[39m\n\u001b[32m    403\u001b[39m scheme = _sniff_scheme(uri)\n\u001b[32m    404\u001b[39m submodule = transport.get_transport(scheme)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m fobj = \u001b[43msubmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransport_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fobj, \u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    407\u001b[39m     fobj.name = uri\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myind\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\smart_open\\local_file.py:34\u001b[39m, in \u001b[36mopen_uri\u001b[39m\u001b[34m(uri_as_string, mode, transport_params)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_uri\u001b[39m(uri_as_string, mode, transport_params):\n\u001b[32m     33\u001b[39m     parsed_uri = parse_uri(uri_as_string)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     fobj = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_uri\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muri_path\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fobj\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin.gz'"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ceb11",
   "metadata": {},
   "source": [
    "Using model('any word') will give word2vec of that word in dataset of google news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace309d",
   "metadata": {},
   "source": [
    "If we use function\n",
    "model.most_similar('any word')\n",
    "it will return list of numbers with similar semantic like women, guy, etc....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48972327",
   "metadata": {},
   "source": [
    "# Implementation from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b10055",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
